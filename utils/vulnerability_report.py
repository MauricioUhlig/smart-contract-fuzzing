import json
import os
import glob
from collections import defaultdict
from typing import Dict, List, Set, Tuple

class ContractErrorAnalyzer:
    def __init__(self):
        self.detected_errors = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))
        self.known_errors = defaultdict(lambda: defaultdict(set))
        self.contract_files = defaultdict(str)
        
        # Define vulnerability categories mapping
        self.vulnerability_categories = {
            'ASSERTION_FAILURE': 'AF',
            'INTEGER_OVERFLOWS': 'IO', 
            'REENTRANCY': 'RE',
            'TRANSACTION_ORDER_DEPENDENCY': 'TD',
            'BLOCK_DEPENDENCY': 'BD',
            'UNHANDLED_EXCEPTION': 'UE',
            'UNSAFE_DELEGATECALL': 'UD',
            'LEAKING_ETHER': 'LE',
            'LOCKING_ETHER': 'LO',
            'UNPROTECTED_SELFDESTRUCT': 'US'
        }
    
    def normalize_vulnerability_name(self, vuln_name: str) -> str:
        """Normalize vulnerability name for comparison"""
        # Replace spaces with underscores and convert to uppercase
        normalized = vuln_name.replace(' ', '_').upper()
        
        # Map to standard category if possible
        for category, code in self.vulnerability_categories.items():
            if category in normalized:
                return code
        return normalized
    
    def load_annotation_file(self, annotation_file_path: str):
        """Load the annotation file with known errors"""
        try:
            with open(annotation_file_path, 'r') as f:
                annotation_data = json.load(f)
            
            # annotation_data is a list of file entries
            for file_entry in annotation_data:
                file_path = file_entry["file"]
                
                for contract_info in file_entry.get("contracts", []):
                    contract_name = contract_info["name"]
                    self.contract_files[contract_name] = file_path
                    
                    # Store known vulnerable lines
                    if "annotations" in contract_info:
                        vulnerable_lines = contract_info["annotations"].get("vulnerable_lines", [])
                        reports = contract_info["annotations"].get("reports", [])
                    
                        # Pair each line with its corresponding report
                        for line, report_type in zip(vulnerable_lines, reports):
                            normalized_type = self.normalize_vulnerability_name(report_type)
                            self.known_errors[contract_name][line].add(normalized_type)
                    
            print(f"Loaded annotations for {len(self.known_errors)} contracts from {annotation_file_path}")
            
        except Exception as e:
            print(f"Error loading annotation file: {e}")
    
    def process_json_files(self, folder_path: str):
        """Process all JSON files in the given folder"""
        json_files = glob.glob(os.path.join(folder_path, "**", "*.json"), recursive=True)
        
        print(f"Found {len(json_files)} JSON files to process")
        
        for json_file in json_files:
            try:
                with open(json_file, 'r') as f:
                    data = json.load(f)
                
                # Each top-level key is a contract name
                for contract_name, contract_data in data.items():
                    # Get algorithm and tag for this analysis run
                    algorithm = contract_data.get("algorithm", "unknown")
                    tag = contract_data.get("tag", "unknown")
                    
                    if "errors" in contract_data:
                        self._process_contract_errors(contract_name, algorithm, tag, contract_data["errors"])
                        
            except Exception as e:
                print(f"Error processing file {json_file}: {e}")
    
    def _process_contract_errors(self, contract_name: str, algorithm: str, tag: str, errors_data: Dict):
        """Process errors for a single contract with specific algorithm and tag"""
        for line_str, error_list in errors_data.items():
            try:
                for error in error_list:
                    # Normalize the vulnerability type
                    normalized_type = self.normalize_vulnerability_name(error['type'])
                    self.detected_errors[contract_name][algorithm][error['line']].add(normalized_type)
                    # Also store by tag for cross-analysis
                    self.detected_errors[contract_name][f"tag_{tag}"][error['line']].add(normalized_type)
            except ValueError:
                print(f"Warning: Invalid line number '{line_str}' in contract '{contract_name}'")
    
    def generate_vulnerability_table(self) -> Dict:
        """Generate vulnerability detection table by algorithm and category"""
        table = {
            "vulnerability_categories": self.vulnerability_categories,
            "algorithm_results": defaultdict(lambda: defaultdict(lambda: {"tp": 0, "fp": 0})),
            "summary": defaultdict(lambda: {"total_tp": 0, "total_fp": 0})
        }
        
        # Initialize all algorithms and categories
        all_algorithms = set()
        for contract_name in self.detected_errors:
            all_algorithms.update(self.detected_errors[contract_name].keys())
        
        # Remove tag entries from algorithm list
        algorithms = [algo for algo in all_algorithms if not algo.startswith("tag_")]
        
        # Process each contract
        for contract_name in self.known_errors:
            known_vulns_by_line = self.known_errors[contract_name]
            
            for algorithm in algorithms:
                if algorithm in self.detected_errors[contract_name]:
                    detected_vulns_by_line = self.detected_errors[contract_name][algorithm]
                    
                    # Check each detected line
                    for line, detected_vuln_types in detected_vulns_by_line.items():
                        known_vuln_types = known_vulns_by_line.get(line, set())
                        
                        for detected_vuln in detected_vuln_types:
                            if detected_vuln in known_vuln_types:
                                # True Positive
                                table["algorithm_results"][algorithm][detected_vuln]["tp"] += 1
                                table["summary"][algorithm]["total_tp"] += 1
                            else:
                                # False Positive
                                table["algorithm_results"][algorithm][detected_vuln]["fp"] += 1
                                table["summary"][algorithm]["total_fp"] += 1
        
        # Convert to regular dict
        table["algorithm_results"] = dict(table["algorithm_results"])
        table["summary"] = dict(table["summary"])
        
        return table
    
    def print_vulnerability_table(self, table: Dict):
        """Print formatted vulnerability detection table"""
        print("=" * 120)
        print("VULNERABILITY DETECTION SUMMARY BY ALGORITHM")
        print("=" * 120)
        
        # Get all algorithms and categories
        algorithms = list(table["algorithm_results"].keys())
        categories = list(self.vulnerability_categories.values())
        
        # Print header
        header = "Algorithm".ljust(20)
        for category in categories:
            header += f" {category}".center(12)
        header += " Total".center(15)
        print(header)
        print("-" * 120)
        
        # Print each algorithm's results
        for algorithm in sorted(algorithms):
            row = f"{algorithm}".ljust(20)
            total_tp = 0
            total_fp = 0
            
            for category in categories:
                results = table["algorithm_results"][algorithm].get(category, {"tp": 0, "fp": 0})
                cell = f"{results['tp']}/{results['fp']}"
                row += f" {cell.center(10)}"
                total_tp += results['tp']
                total_fp += results['fp']
            
            # Add total column
            total_cell = f"{total_tp}/{total_fp}"
            row += f" {total_cell.center(13)}"
            print(row)
        
        print("-" * 120)
        
        # Print category descriptions
        print("\nVULNERABILITY CATEGORIES:")
        for full_name, code in self.vulnerability_categories.items():
            readable_name = full_name.replace('_', ' ').title()
            print(f"  {code}: {readable_name}")
    
    def generate_report(self) -> Dict:
        """Generate comprehensive statistics report"""
        report = {
            "summary": {
                "total_contracts_with_annotations": len(self.known_errors),
                "total_contracts_with_detections": len(self.detected_errors),
                "total_known_errors": 0,
                "overall_accuracy_percentage": 0.0
            },
            "contract_comparison": {},
            "algorithm_comparison": defaultdict(lambda: {
                "contracts_analyzed": 0,
                "total_true_positives": 0,
                "total_false_positives": 0,
                "total_false_negatives": 0,
                "accuracy_percentage": 0.0,
                "precision_percentage": 0.0,
                "recall_percentage": 0.0
            }),
            "tag_comparison": defaultdict(lambda: {
                "contracts_analyzed": 0,
                "total_true_positives": 0,
                "total_false_positives": 0,
                "total_false_negatives": 0,
                "accuracy_percentage": 0.0,
                "precision_percentage": 0.0,
                "recall_percentage": 0.0
            }),
            "best_performers": {
                "by_contract": {},
                "by_algorithm": {},
                "by_tag": {}
            },
            "vulnerability_table": {}
        }
        
        # Calculate statistics per contract and compare algorithms
        all_contracts = set(list(self.known_errors.keys()) + list(self.detected_errors.keys()))
        
        for contract_name in all_contracts:
            known_lines = set(self.known_errors[contract_name].keys())
            report["contract_comparison"][contract_name] = {
                "file": self.contract_files.get(contract_name, "Unknown"),
                "known_vulnerable_lines": len(known_lines),
                "known_vulnerabilities": {line: list(errors) for line, errors in self.known_errors[contract_name].items()},
                "algorithm_results": {},
                "best_algorithm": None,
                "best_accuracy": 0.0
            }
            
            # Update total known errors
            report["summary"]["total_known_errors"] += len(known_lines)
            
            # Compare all algorithms for this contract
            algorithms_for_contract = list(self.detected_errors[contract_name].keys())
            
            for algorithm in algorithms_for_contract:
                detected_lines = set(self.detected_errors[contract_name][algorithm].keys())
                
                # Calculate metrics
                true_positive_lines = known_lines & detected_lines
                false_positive_lines = detected_lines - known_lines
                false_negative_lines = known_lines - detected_lines
                
                true_positive_count = len(true_positive_lines)
                false_positive_count = len(false_positive_lines)
                false_negative_count = len(false_negative_lines)
                
                # Calculate percentages
                accuracy = (true_positive_count / len(known_lines) * 100) if known_lines else 0.0
                precision = (true_positive_count / (true_positive_count + false_positive_count) * 100) if (true_positive_count + false_positive_count) > 0 else 0.0
                recall = (true_positive_count / (true_positive_count + false_negative_count) * 100) if (true_positive_count + false_negative_count) > 0 else 0.0
                
                # Store results for this algorithm on this contract
                report["contract_comparison"][contract_name]["algorithm_results"][algorithm] = {
                    "true_positives": true_positive_count,
                    "false_positives": false_positive_count,
                    "false_negatives": false_negative_count,
                    "accuracy_percentage": round(accuracy, 2),
                    "precision_percentage": round(precision, 2),
                    "recall_percentage": round(recall, 2),
                    "detected_lines": list(detected_lines),
                    "true_positive_lines": list(true_positive_lines),
                    "false_positive_lines": list(false_positive_lines),
                    "false_negative_lines": list(false_negative_lines)
                }
                
                # Update algorithm comparison
                report["algorithm_comparison"][algorithm]["contracts_analyzed"] += 1
                report["algorithm_comparison"][algorithm]["total_true_positives"] += true_positive_count
                report["algorithm_comparison"][algorithm]["total_false_positives"] += false_positive_count
                report["algorithm_comparison"][algorithm]["total_false_negatives"] += false_negative_count
                
                # Update tag comparison (if algorithm starts with "tag_")
                if algorithm.startswith("tag_"):
                    tag = algorithm[4:]  # Remove "tag_" prefix
                    report["tag_comparison"][tag]["contracts_analyzed"] += 1
                    report["tag_comparison"][tag]["total_true_positives"] += true_positive_count
                    report["tag_comparison"][tag]["total_false_positives"] += false_positive_count
                    report["tag_comparison"][tag]["total_false_negatives"] += false_negative_count
                
                # Track best algorithm for this contract
                if accuracy > report["contract_comparison"][contract_name]["best_accuracy"]:
                    report["contract_comparison"][contract_name]["best_accuracy"] = round(accuracy, 2)
                    report["contract_comparison"][contract_name]["best_algorithm"] = algorithm
        
        # Calculate aggregate metrics for algorithms
        for algorithm, stats in report["algorithm_comparison"].items():
            if not algorithm.startswith("tag_"):  # Don't process tags in algorithm comparison
                total_known = stats["total_true_positives"] + stats["total_false_negatives"]
                total_detected = stats["total_true_positives"] + stats["total_false_positives"]
                
                if total_known > 0:
                    stats["accuracy_percentage"] = round((stats["total_true_positives"] / total_known) * 100, 2)
                    stats["recall_percentage"] = round((stats["total_true_positives"] / total_known) * 100, 2)
                
                if total_detected > 0:
                    stats["precision_percentage"] = round((stats["total_true_positives"] / total_detected) * 100, 2)
        
        # Calculate aggregate metrics for tags
        for tag, stats in report["tag_comparison"].items():
            total_known = stats["total_true_positives"] + stats["total_false_negatives"]
            total_detected = stats["total_true_positives"] + stats["total_false_positives"]
            
            if total_known > 0:
                stats["accuracy_percentage"] = round((stats["total_true_positives"] / total_known) * 100, 2)
                stats["recall_percentage"] = round((stats["total_true_positives"] / total_known) * 100, 2)
            
            if total_detected > 0:
                stats["precision_percentage"] = round((stats["total_true_positives"] / total_detected) * 100, 2)
        
        # Find best performers
        self._calculate_best_performers(report)
        
        # Generate vulnerability table
        report["vulnerability_table"] = self.generate_vulnerability_table()
        
        # Convert defaultdict to regular dict for JSON serialization
        report["algorithm_comparison"] = dict(report["algorithm_comparison"])
        report["tag_comparison"] = dict(report["tag_comparison"])
        
        return report
    
    def _calculate_best_performers(self, report: Dict):
        """Calculate best performing algorithms and tags"""
        # Best algorithm by accuracy
        best_algorithm = None
        best_algorithm_accuracy = 0.0
        
        for algorithm, stats in report["algorithm_comparison"].items():
            if not algorithm.startswith("tag_") and stats["contracts_analyzed"] > 0:
                if stats["accuracy_percentage"] > best_algorithm_accuracy:
                    best_algorithm_accuracy = stats["accuracy_percentage"]
                    best_algorithm = algorithm
        
        if best_algorithm:
            report["best_performers"]["by_algorithm"] = {
                "algorithm": best_algorithm,
                "accuracy": best_algorithm_accuracy,
                "precision": report["algorithm_comparison"][best_algorithm]["precision_percentage"],
                "recall": report["algorithm_comparison"][best_algorithm]["recall_percentage"]
            }
        
        # Best tag by accuracy
        best_tag = None
        best_tag_accuracy = 0.0
        
        for tag, stats in report["tag_comparison"].items():
            if stats["contracts_analyzed"] > 0 and stats["accuracy_percentage"] > best_tag_accuracy:
                best_tag_accuracy = stats["accuracy_percentage"]
                best_tag = tag
        
        if best_tag:
            report["best_performers"]["by_tag"] = {
                "tag": best_tag,
                "accuracy": best_tag_accuracy,
                "precision": report["tag_comparison"][best_tag]["precision_percentage"],
                "recall": report["tag_comparison"][best_tag]["recall_percentage"]
            }
    
    def print_detailed_report(self, report: Dict):
        """Print a formatted detailed report"""
        print("=" * 80)
        print("MULTI-ALGORITHM CONTRACT VULNERABILITY ANALYSIS REPORT")
        print("=" * 80)
        
        # Print vulnerability table first
        self.print_vulnerability_table(report["vulnerability_table"])
        
        # Summary section
        summary = report["summary"]
        
        print(f"\nOVERALL SUMMARY:")
        print(f"  Contracts with annotations: {summary['total_contracts_with_annotations']}")
        print(f"  Contracts with detections: {summary['total_contracts_with_detections']}")
        print(f"  Total known vulnerable lines: {summary['total_known_errors']}")
        
        # Best performers
        print(f"\nBEST PERFORMERS:")
        if report["best_performers"]["by_algorithm"]:
            best_algo = report["best_performers"]["by_algorithm"]
            print(f"  Best Algorithm: {best_algo['algorithm']} "
                  f"(Accuracy: {best_algo['accuracy']}%, "
                  f"Precision: {best_algo['precision']}%, "
                  f"Recall: {best_algo['recall']}%)")
        
        if report["best_performers"]["by_tag"]:
            best_tag = report["best_performers"]["by_tag"]
            print(f"  Best Tag: {best_tag['tag']} "
                  f"(Accuracy: {best_tag['accuracy']}%, "
                  f"Precision: {best_tag['precision']}%, "
                  f"Recall: {best_tag['recall']}%)")
        
        # Algorithm Comparison
        print(f"\nALGORITHM COMPARISON (Statistical Results):")
        print("-" * 80)
        for algorithm, stats in report["algorithm_comparison"].items():
            if not algorithm.startswith("tag_") and stats["contracts_analyzed"] > 0:
                print(f"\nAlgorithm: {algorithm}")
                print(f"  Contracts Analyzed: {stats['contracts_analyzed']}")
                print(f"  True Positives: {stats['total_true_positives']}")
                print(f"  False Positives: {stats['total_false_positives']}")
                print(f"  False Negatives: {stats['total_false_negatives']}")
                print(f"  Accuracy: {stats['accuracy_percentage']}%")
                print(f"  Precision: {stats['precision_percentage']}%")
                print(f"  Recall: {stats['recall_percentage']}%")
        
        # Contract-by-contract comparison
        print(f"\nCONTRACT-BY-CONTRACT COMPARISON:")
        print("-" * 80)
        
        for contract_name, contract_data in report["contract_comparison"].items():
            print(f"\nContract: {contract_name}")
            print(f"File: {contract_data['file']}")
            print(f"Known Vulnerable Lines: {contract_data['known_vulnerable_lines']}")
            print(f"Best Algorithm: {contract_data['best_algorithm']} "
                  f"(Accuracy: {contract_data['best_accuracy']}%)")
            
            for algorithm, results in contract_data["algorithm_results"].items():
                if not algorithm.startswith("tag_"):  # Only show algorithms, not tags
                    print(f"  {algorithm}: "
                          f"TP={results['true_positives']}, "
                          f"FP={results['false_positives']}, "
                          f"FN={results['false_negatives']}, "
                          f"Acc={results['accuracy_percentage']}%")

def main():
    # Configuration - UPDATE THESE PATHS
    JSON_FOLDER = "results"  # Folder containing analysis JSON files
    ANNOTATION_FILE = "utils/result.json"  # Annotation metadata file
    
    analyzer = ContractErrorAnalyzer()
    
    # Load known annotations
    analyzer.load_annotation_file(ANNOTATION_FILE)
    
    # Process JSON files with detected errors
    analyzer.process_json_files(JSON_FOLDER)
    
    # Generate and print report
    report = analyzer.generate_report()
    analyzer.print_detailed_report(report)
    
    # Save detailed report to file
    with open("multi_algorithm_analysis_report.json", "w") as f:
        json.dump(report, f, indent=2)
    
    print(f"\nDetailed report saved to: multi_algorithm_analysis_report.json")
    
    # Print quick statistical summary
    print(f"\nSTATISTICAL SUMMARY:")
    print(f"Total Contracts with Annotations: {report['summary']['total_contracts_with_annotations']}")
    print(f"Total Known Vulnerabilities: {report['summary']['total_known_errors']}")
    
    if report["best_performers"]["by_algorithm"]:
        best = report["best_performers"]["by_algorithm"]
        print(f"Overall Best Algorithm: {best['algorithm']} "
              f"(Accuracy: {best['accuracy']}%, Precision: {best['precision']}%, Recall: {best['recall']}%)")

if __name__ == "__main__":
    main()